{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ba5b91-9a14-4add-a766-5c9a231c80e6",
   "metadata": {},
   "source": [
    "<font color=\"blue\"><b> Wide Versus Narrow Transformation </b> </font>\n",
    "\n",
    "__Narrow Transformations__ convert each input partition to only one output partition.\n",
    "\n",
    "\n",
    "1. This kind of transformation is basically fast.\n",
    "2. Does not require any data shuffling over the cluster network or no data movement.\n",
    "3. Operation of map()and filter() belongs to this transformations.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6143e55-09dd-4253-9bb1-cb4f4deb8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\",\"false\")\n",
    "ratingDF = spark.read.option(\"header\",\"true\").csv(\"spark-data/ratings.csv\")\n",
    "\n",
    "from pyspark.sql.functions import * \n",
    "\n",
    "orderDF = ratingDF \\\n",
    ".filter(col(\"rating\") > 3) \\\n",
    ".show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde1c5d-f166-4e0f-8fb6-58c3a9a9d6c4",
   "metadata": {},
   "source": [
    "<font color=\"sky blue\">___Did you noticed there are two jobs because of above code.\n",
    "Both Jobs have 1 stage each___</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c1e55-38b5-496f-9d75-30c5a13d7e7c",
   "metadata": {},
   "source": [
    "<font color=\"blue\">__Wide Transformations__</font>\n",
    "This type of transformation will have input partitions contributing to many output partitions.\n",
    "\n",
    "1. Slow as compare to narrow dependencies speed might be significantly affected as it might be required to shuffle data around different nodes when creating new partitions.\n",
    "2. Require data shuffling over the cluster network\n",
    "3. Functions such as groupByKey(), aggregateByKey(), aggregate(), join(), repartition() are some examples of wider transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e094cd-fee7-4e04-b144-67feb1672856",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\",\"false\")\n",
    "spark.read.option(\"header\",\"true\").csv(\"spark-data/ratings.csv\") \\\n",
    ".filter(\"rating > 3\") \\\n",
    ".groupBy(\"rating\") \\\n",
    ".count() \\\n",
    ".write.csv(\"spark-data/output1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5aef61-1f52-4a2d-9016-3fa326e505d9",
   "metadata": {},
   "source": [
    "<font color=\"sky blue\">___Did you noticed above code triggers two jobs\n",
    "1st Job has 1 stage and second job has 2 stages.___</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b999d7-f37c-433a-9766-7ba93b6b0d14",
   "metadata": {},
   "source": [
    "Formula's \n",
    "\n",
    "##### ___No of Jobs = No of Actions___\n",
    "##### ___No of Stage in each Job = 1+ No of Wide Transformation___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c847615-873a-4a2b-9536-eabd557104ec",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7200af-f7d5-4b13-8b3b-8a5829c686cb",
   "metadata": {},
   "source": [
    "Run below code and find out whether ___dropDuplicate___ is a narrow or wide transformation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c76af43d-c980-4c5b-abee-8216d3eb1596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|   100|     82|   4.0| 862168835|\n",
      "|  1000|    327|   3.0|1111553316|\n",
      "| 10005|   1013|   4.0|1533926930|\n",
      "| 10005|  31696|   5.0|1533923595|\n",
      "| 10005|   4018|   3.0|1533924263|\n",
      "| 10008|    163|   4.0|1026239826|\n",
      "| 10008|   1914|   4.0|1026239611|\n",
      "| 10008|   4641|   4.0|1025727747|\n",
      "| 10009|   1690|   3.0| 902036728|\n",
      "| 10009|   1783|   1.0| 902035522|\n",
      "| 10012| 154941|   3.0|1477521569|\n",
      "| 10012|   8970|   3.0|1477519630|\n",
      "| 10013| 104841|   5.0|1518315898|\n",
      "| 10013|   1884|   4.5|1518316110|\n",
      "| 10013|   3448|   4.0|1518316478|\n",
      "| 10013|  84152|   3.5|1518316235|\n",
      "| 10014|   1090|   3.5|1422234430|\n",
      "| 10018|   1197|   3.0| 975650759|\n",
      "| 10018|    818|   2.0| 976165700|\n",
      "| 10028|   1198|   5.0| 944901571|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratingDF= spark.read.option(\"header\",\"true\").csv(\"/user/training/spark-data/ratings.csv\")\n",
    "\n",
    "ratingDF \\\n",
    ".dropDuplicates() \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0cbd61-6767-4879-97ff-6423e935aa1e",
   "metadata": {},
   "source": [
    "Run below code and check out Spark UI to find out how many stages created and how many shuffles happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbede735-084d-43d6-afb1-935d4987e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingDF= spark.read.option(\"header\",\"true\").csv(\"/user/training/spark-data/ratings.csv\")\n",
    "\n",
    "ratingDF \\\n",
    ".filter(\"rating>4\") \\\n",
    ".count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f8e31-ecd2-4ce2-8e84-fd2e46d34bb0",
   "metadata": {},
   "source": [
    "Did you noticed above code gave us back a number, which means this count is an action. \n",
    "There is no wide transformation in above code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
